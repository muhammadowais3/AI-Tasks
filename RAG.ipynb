{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "638ad3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_path= r\"/home/asad/projects/Owais AI trial tasks/RAG pipeline/data/indo-pak-histoy.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dcfde87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, fitz\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from whoosh.fields import Schema, TEXT, ID\n",
    "from whoosh.analysis import StemmingAnalyzer\n",
    "from whoosh.index import create_in, open_dir, exists_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8724cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_DIR = \"/home/asad/projects/Owais AI trial tasks/RAG pipeline/chroma_db\"\n",
    "WHOOSH_DIR = \"/home/asad/projects/Owais AI trial tasks/RAG pipeline/whoosh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee8337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def load_text(file_path):\n",
    "#     ext = file_path.lower().split('.')[-1]\n",
    "#     if ext == \"pdf\":\n",
    "#         doc = fitz.open(file_path)\n",
    "#         return \"\\n\".join([page.get_text() for page in doc])\n",
    "#     elif ext in {\"txt\", \"md\"}:\n",
    "#         with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#             return f.read()\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file\")\n",
    "\n",
    "def load_text(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        doc = fitz.open(file_path)\n",
    "        return \"\\n\".join([p.get_text() for p in doc])\n",
    "    elif ext in {\".txt\", \".md\"}:\n",
    "        with open(file_path, encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type '{ext}' ‚Äì supported: .pdf, .txt, .md\")\n",
    "\n",
    "def chunk_text(text, source):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    return splitter.create_documents([text], metadatas=[{\"source\": source}])\n",
    "\n",
    "def build_chroma(chunks):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectordb = Chroma.from_documents(chunks, embedding=embeddings, persist_directory=CHROMA_DIR)\n",
    "    vectordb.persist()\n",
    "\n",
    "def build_whoosh(chunks):\n",
    "    if not os.path.exists(WHOOSH_DIR):\n",
    "        os.mkdir(WHOOSH_DIR)\n",
    "        schema = Schema(content=TEXT(analyzer=StemmingAnalyzer()), source=ID(stored=True))\n",
    "        ix = create_in(WHOOSH_DIR, schema)\n",
    "    else:\n",
    "        ix = open_dir(WHOOSH_DIR)\n",
    "\n",
    "    writer = ix.writer()\n",
    "    for chunk in chunks:\n",
    "        writer.add_document(content=chunk.page_content, source=chunk.metadata[\"source\"])\n",
    "    writer.commit()\n",
    "\n",
    "def ingest(file_path):\n",
    "    text = load_text(file_path)\n",
    "    chunks = chunk_text(text, os.path.basename(file_path))\n",
    "    build_chroma(chunks)\n",
    "    build_whoosh(chunks)\n",
    "    print(f\"Ingested: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1963d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.index import create_in, open_dir, exists_in\n",
    "\n",
    "def build_whoosh(chunks):\n",
    "    if not os.path.exists(WHOOSH_DIR):\n",
    "        os.makedirs(WHOOSH_DIR)\n",
    "    if not exists_in(WHOOSH_DIR):\n",
    "        schema = Schema(content=TEXT(analyzer=StemmingAnalyzer()), source=ID(stored=True))\n",
    "        ix = create_in(WHOOSH_DIR, schema)\n",
    "    else:\n",
    "        ix = open_dir(WHOOSH_DIR)\n",
    "\n",
    "    writer = ix.writer()\n",
    "    for chunk in chunks:\n",
    "        writer.add_document(content=chunk.page_content, source=chunk.metadata[\"source\"])\n",
    "    writer.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18213a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2705c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_459045/109738951.py:30: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested: /home/asad/projects/Owais AI trial tasks/RAG pipeline/data/indo-pak-histoy.pdf\n",
      "Ingested: /home/asad/projects/Owais AI trial tasks/RAG pipeline/data/indo pak txt.txt\n",
      "Ingested: /home/asad/projects/Owais AI trial tasks/RAG pipeline/data/richtext_converted_to_markdown.md\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "        \"/home/asad/projects/Owais AI trial tasks/RAG pipeline/data/indo-pak-histoy.pdf\",\n",
    "        \"/home/asad/projects/Owais AI trial tasks/RAG pipeline/data/indo pak txt.txt\",\n",
    "        \"/home/asad/projects/Owais AI trial tasks/RAG pipeline/data/richtext_converted_to_markdown.md\"\n",
    "\n",
    "    ]\n",
    "for file in files:\n",
    "    ingest(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7abcc011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag_query.py\n",
    "\n",
    "import openai\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from chromadb import PersistentClient\n",
    "from whoosh.index import open_dir\n",
    "from whoosh.qparser import QueryParser\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from openai import OpenAI\n",
    "openai_client = OpenAI()\n",
    "# CHROMA_DIR = \"chroma_store\"\n",
    "# WHOOSH_DIR = \"whoosh_index\"\n",
    "# openai.api_key = \"your-openai-key\"\n",
    "\n",
    "def bm25_search(query):\n",
    "    ix = open_dir(WHOOSH_DIR)\n",
    "    with ix.searcher() as searcher:\n",
    "        parser = QueryParser(\"content\", schema=ix.schema)\n",
    "        q = parser.parse(query)\n",
    "        results = searcher.search(q, limit=5)\n",
    "        return [{\"text\": r[\"content\"], \"source\": r[\"source\"]} for r in results]\n",
    "\n",
    "def vector_search(query, embedding):\n",
    "    db = Chroma(persist_directory=CHROMA_DIR, embedding_function=embedding)\n",
    "    results = db.similarity_search_with_score(query, k=5)\n",
    "    return [{\"text\": r[0].page_content, \"source\": r[0].metadata[\"source\"], \"score\": r[1]} for r in results]\n",
    "\n",
    "def rerank(all_docs, query, embeddings):\n",
    "    q_vec = embeddings.embed_query(query)\n",
    "    doc_vecs = [embeddings.embed_query(doc[\"text\"]) for doc in all_docs]\n",
    "    scores = cosine_similarity([q_vec], doc_vecs)[0]\n",
    "    for i, score in enumerate(scores):\n",
    "        all_docs[i][\"confidence\"] = round(float(score), 2)\n",
    "    return sorted(all_docs, key=lambda x: -x[\"confidence\"])\n",
    "\n",
    "def generate_response(query, top_docs):\n",
    "    context = \"\\n\\n\".join(f\"[{d['source']}]\\n{d['text']}\" for d in top_docs)\n",
    "    prompt = f\"Use the following context to answer:\\n{context}\\n\\nQ: {query}\\nA:\"\n",
    "\n",
    "    resp = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3,\n",
    "        stream=False  # change to True if you want streaming output\n",
    "    )\n",
    "\n",
    "    return resp.choices[0].message\n",
    "\n",
    "def query_rag(query):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    docs = bm25_search(query) + vector_search(query, embeddings)\n",
    "    print(docs)\n",
    "    if not docs:\n",
    "        return \"No results found.\", []\n",
    "    ranked = rerank(docs, query, embeddings)[:3]\n",
    "    answer = generate_response(query, ranked)\n",
    "    return answer, ranked\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9db08dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': '(founded in 1906) played pivotal roles. While Congress aimed for a unified Indian independence, the Muslim League feared marginalization of\\n\\nMuslims in a Hindu-majority India.\\n\\n2\\\\. Partition of British India ‚Äì 1947\\n\\nThe demand for a separate Muslim state, Pakistan, was formally introduced by Muhammad Ali Jinnah in the Lahore Resolution (1940). Astensions grew, the British decided to leave India, leading to the Mountbatten Plan (1947), which resulted in the partition into India and Pakistan.', 'source': 'richtext_converted_to_markdown.md', 'score': 0.4264531433582306}, {'text': '(founded in 1906) played pivotal roles. While Congress aimed for a unified Indian independence, the Muslim League feared marginalization of\\n\\nMuslims in a Hindu-majority India.\\n\\n2\\\\. Partition of British India ‚Äì 1947\\n\\nThe demand for a separate Muslim state, Pakistan, was formally introduced by Muhammad Ali Jinnah in the Lahore Resolution (1940). Astensions grew, the British decided to leave India, leading to the Mountbatten Plan (1947), which resulted in the partition into India and Pakistan.', 'source': 'richtext_converted_to_markdown.md', 'score': 0.4264531433582306}, {'text': '(founded in 1906) played pivotal roles. While Congress aimed for a unified Indian independence, the Muslim League feared marginalization of\\n\\nMuslims in a Hindu-majority India.\\n\\n2\\\\. Partition of British India ‚Äì 1947\\n\\nThe demand for a separate Muslim state, Pakistan, was formally introduced by Muhammad Ali Jinnah in the Lahore Resolution (1940). Astensions grew, the British decided to leave India, leading to the Mountbatten Plan (1947), which resulted in the partition into India and Pakistan.', 'source': 'richtext_converted_to_markdown.md', 'score': 0.42667555809020996}, {'text': \"over Kashmir‚Äîin 1965 and 1999 (Kargil conflict).\\n4. Wars and Military Clashes\\n1.\\nFirst War (1947‚Äì48): Fought over Kashmir; ended in UN-brokered ceasefire.2.\\nSecond War (1965): Triggered by Pakistan's Operation Gibraltar in Kashmir; resulted in Tashkent Agreement mediated by the USSR.\\n3.\\nThird War (1971): Related to the Bangladesh Liberation War. India supported East Pakistan's independence movement, resulting in Pakistan‚Äôs\\ndefeat and the creation of Bangladesh.\\n4.\", 'source': 'indo pak txt.txt', 'score': 0.42747393250465393}, {'text': \"over Kashmir‚Äîin 1965 and 1999 (Kargil conflict).\\n4. Wars and Military Clashes\\n1.\\nFirst War (1947‚Äì48): Fought over Kashmir; ended in UN-brokered ceasefire.2.\\nSecond War (1965): Triggered by Pakistan's Operation Gibraltar in Kashmir; resulted in Tashkent Agreement mediated by the USSR.\\n3.\\nThird War (1971): Related to the Bangladesh Liberation War. India supported East Pakistan's independence movement, resulting in Pakistan‚Äôs\\ndefeat and the creation of Bangladesh.\\n4.\", 'source': 'indo pak txt.txt', 'score': 0.42747393250465393}]\n",
      "üîç Answer:\n",
      " ChatCompletionMessage(content='In 1947, the partition of British India occurred, leading to the creation of two independent states: India and Pakistan. This was a result of growing tensions between the Indian National Congress, which sought a unified India, and the Muslim League, which, led by Muhammad Ali Jinnah, demanded a separate Muslim state due to fears of marginalization in a Hindu-majority India. The partition was formalized through the Mountbatten Plan, which facilitated the British withdrawal from India.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n",
      "\n",
      "üìö Sources:\n",
      "richtext_converted_to_markdown.md | Confidence: 0.79\n",
      "richtext_converted_to_markdown.md | Confidence: 0.79\n",
      "richtext_converted_to_markdown.md | Confidence: 0.79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q = \"what happened in 1947?\"\n",
    "answer, sources = query_rag(q)\n",
    "print(\"üîç Answer:\\n\", answer)\n",
    "print(\"\\nüìö Sources:\")\n",
    "for s in sources:\n",
    "    print(f\"{s['source']} | Confidence: {s['confidence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1caf884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b53b18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
